{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FadilSeputra/braisee-machine-learning/blob/main/offline_road.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLU9pspfkDGU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1gWZsUWmE1s",
        "outputId": "6fea49d3-c1f5-4059-afae-94f43ae280f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRonrzAxmG-Q"
      },
      "source": [
        "# Preprocessing Gambar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7iL9hmBmGIV"
      },
      "outputs": [],
      "source": [
        "def preprocess_image_mobile(image):\n",
        "    # Resize gambar dari kamera\n",
        "    height, width = image.shape[:2]\n",
        "    if max(height, width) > 640:  # Maksimal resolusi\n",
        "        scale = 640 / max(height, width)\n",
        "        image = cv2.resize(image, (int(width * scale), int(height * scale)))\n",
        "    if len(image.shape) == 3:\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_image = image\n",
        "\n",
        "    _, binary_image = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY_INV)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    clean_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
        "    contrast_image = cv2.convertScaleAbs(clean_image, alpha=2, beta=0)  # Penajaman kontras\n",
        "    normalized_image = image / 255.0  # Skala nilai pixel ke rentang [0, 1]\n",
        "\n",
        "    return normalized_image, binary_image  # Return both images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te_a4Vn_ne2f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g0D94_EnjpS"
      },
      "source": [
        "# Algoritma untuk Sliding Window dan Deteksi Bounding Box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puPELmQCny-k"
      },
      "outputs": [],
      "source": [
        "# def sliding_window_mobile(image, step_size, initial_box_size, max_box_size, model,max_iterations=50):\n",
        "#     height, width = image.shape\n",
        "#     detected_boxes = []\n",
        "#     predictions = []\n",
        "#     box_size = initial_box_size\n",
        "#     iteration = 0\n",
        "\n",
        "#     while box_size <= max_box_size and iteration < max_iterations:\n",
        "#         for y in range(0, height - box_size + 1, step_size):\n",
        "#             for x in range(0, width - box_size + 1, step_size):\n",
        "#                 roi = image[y:y + box_size, x:x + box_size]\n",
        "#                 roi_resized = cv2.resize(roi, (28, 28))  # Ubah ukuran hasil ekstrasi agar sesuai model cnn yang telah dibuat\n",
        "#                 roi_normalized = roi_resized / 255.0\n",
        "#                 roi_input = np.expand_dims(roi_normalized, axis=(0, -1))\n",
        "\n",
        "#                 prediction = model.predict(roi_input, verbose=0)\n",
        "#                 predicted_class = np.argmax(prediction)\n",
        "#                 confidence = np.max(prediction)\n",
        "\n",
        "#                 if predicted_class !=26 and confidence > 0.5:  # 0 adalah \"tidak ada huruf\"\n",
        "#                     detected_boxes.append((x, y, x + box_size, y + box_size))\n",
        "#                     predictions.append((predicted_class, confidence))\n",
        "\n",
        "#         if predictions:\n",
        "#             break\n",
        "#         box_size += step_size  # memperbesar bounding box\n",
        "#         iteration += 1\n",
        "\n",
        "#     return detected_boxes, predictions\n",
        "\n",
        "def sliding_window_mobile(image, step_size, initial_box_size, max_box_size, model, max_iterations=50):\n",
        "    height, width = image.shape\n",
        "    detected_boxes = []\n",
        "    predictions = []\n",
        "    box_size = initial_box_size\n",
        "    iteration = 0\n",
        "\n",
        "    while box_size <= max_box_size and iteration < max_iterations:\n",
        "        for y in range(0, height - box_size + 1, step_size):\n",
        "            for x in range(0, width - box_size + 1, step_size):\n",
        "                roi = image[y:y + box_size, x:x + box_size]\n",
        "                roi_resized = cv2.resize(roi, (28, 28))  # Adjust size to match model input\n",
        "                roi_normalized = roi_resized / 255.0  # Normalize image to [0, 1]\n",
        "\n",
        "                # Convert to INT8 format: scale and shift values to [-128, 127] if model expects INT8\n",
        "                roi_int8 = np.round(roi_normalized * 255).astype(np.int8)  # Convert to INT8\n",
        "\n",
        "                # Ensure the shape is (1, 28, 28, 1) for the model\n",
        "                roi_input = np.expand_dims(roi_int8, axis=(0, -1))\n",
        "\n",
        "                # Get input and output details\n",
        "                input_details = model.get_input_details()\n",
        "                output_details = model.get_output_details()\n",
        "\n",
        "                # Set input tensor\n",
        "                model.set_tensor(input_details[0]['index'], roi_input)\n",
        "\n",
        "                # Run inference\n",
        "                model.invoke()\n",
        "\n",
        "                # Get the output tensor\n",
        "                prediction = model.get_tensor(output_details[0]['index'])\n",
        "                predicted_class = np.argmax(prediction)\n",
        "                confidence = np.max(prediction)\n",
        "\n",
        "                if predicted_class != 26 and confidence > 0.5:  # Class 26 is \"empty\"\n",
        "                    detected_boxes.append((x, y, x + box_size, y + box_size))\n",
        "                    predictions.append((predicted_class, confidence))\n",
        "\n",
        "        if predictions:\n",
        "            break\n",
        "\n",
        "        box_size += step_size  # Increase box size for the next iteration\n",
        "        iteration += 1\n",
        "\n",
        "    return detected_boxes, predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9rwYbVwoVnc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvIeb_Fs9v0M"
      },
      "source": [
        "# penyusunan gambar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAl4ak7t90_2"
      },
      "outputs": [],
      "source": [
        "def construct_sentence_mobile(bounding_boxes, predictions, class_mapping):\n",
        "    # Sort bounding boxes\n",
        "    sorted_indices = sorted(range(len(bounding_boxes)), key=lambda i: (bounding_boxes[i][1], bounding_boxes[i][0]))\n",
        "    sentence = []\n",
        "    for i in sorted_indices:\n",
        "        pred_class = predictions[i][0]\n",
        "        if pred_class in class_mapping:\n",
        "            sentence.append(class_mapping[pred_class])\n",
        "        else:\n",
        "            print(f\"Warning: Predicted class {pred_class} not found in class_mapping.\")\n",
        "\n",
        "    # Return the constructed sentence\n",
        "    return ''.join(sentence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWfHE0Wl9_7J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kesQ-AWN-B94"
      },
      "source": [
        "# main pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZcWoZ4r-Gro"
      },
      "outputs": [],
      "source": [
        "def main_pipeline_mobile(image_path, tflite_model_path, class_mapping):\n",
        "    # Preprocessing\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Image not loaded. Check the image path.\")\n",
        "        return\n",
        "\n",
        "    image, thresh = preprocess_image_mobile(image)\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        model = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "        model.allocate_tensors()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    # Sliding window\n",
        "    detected_boxes, predictions = sliding_window_mobile(\n",
        "        thresh, step_size=2, initial_box_size=20, max_box_size=128, model=model\n",
        "    )\n",
        "    print(f\"Detected boxes: {detected_boxes}\")\n",
        "    print(f\"Predictions: {predictions}\")\n",
        "\n",
        "    # Construct sentence from detected boxes and predictions\n",
        "    sentence = construct_sentence_mobile(detected_boxes, predictions, class_mapping)\n",
        "    print(f\"Constructed sentence: {sentence}\")\n",
        "\n",
        "    # Visualize result (overlay sentence and boxes on image)\n",
        "    display_result_mobile(image, sentence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc4UU0VH-T8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3Ui12qlB7b7"
      },
      "source": [
        "# class mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "muD274XBB_E2",
        "outputId": "71a6431d-8de0-41be-97a1-f5364814fbc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected boxes: [(80, 34, 100, 54), (82, 34, 102, 54), (84, 34, 104, 54), (86, 34, 106, 54), (88, 34, 108, 54), (90, 34, 110, 54), (92, 34, 112, 54), (94, 34, 114, 54), (96, 34, 116, 54), (98, 34, 118, 54), (100, 34, 120, 54), (102, 34, 122, 54), (106, 34, 126, 54), (220, 42, 240, 62), (76, 50, 96, 70), (80, 50, 100, 70), (54, 246, 74, 266), (62, 248, 82, 268), (76, 250, 96, 270), (78, 250, 98, 270), (80, 250, 100, 270), (148, 250, 168, 270), (92, 262, 112, 282)]\n",
            "Predictions: [(10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (10, 16), (0, 59), (0, 26), (10, 83), (10, 92), (10, 101), (10, 49), (10, 63), (10, 47), (4, 36)]\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 0 not found in class_mapping.\n",
            "Warning: Predicted class 0 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 10 not found in class_mapping.\n",
            "Warning: Predicted class 4 not found in class_mapping.\n",
            "Constructed sentence: \n",
            "Detected sentence: \n"
          ]
        }
      ],
      "source": [
        "# model label\n",
        "map={'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8,\n",
        "                  'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17,\n",
        "                  's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'empty': 26}\n",
        "model_path=\"/content/drive/MyDrive/Braille_image_classifier_1_fix_quantized.tflite\"\n",
        "image =\"/content/drive/MyDrive/images/train/0000000.jpg\"\n",
        "main_pipeline_mobile(image,model_path,map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAH6eRjOEUyV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2SEy9VFEVZM"
      },
      "source": [
        "# model doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h8RammiEbIt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4t0TTYpEkZG"
      },
      "outputs": [],
      "source": [
        "def load_and_label_image(image_path, label):\n",
        "    img = load_img(image_path, target_size=(28, 28), color_mode='grayscale')\n",
        "    img_array = img_to_array(img) / 255.0  # Normalisasi gambar\n",
        "    return img_array, label\n",
        "\n",
        "def generate_labels_from_filenames(image_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8,\n",
        "                  'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17,\n",
        "                  's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'empty': 26}\n",
        "\n",
        "    for filename in os.listdir(image_dir):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        # Jika file adalah gambar kosong (misalnya, \"kosong.jpg\" atau gambar dengan label \"empty\")\n",
        "        if filename.startswith(\"empty\"):\n",
        "            label = label_dict['empty']\n",
        "        elif filename.endswith('.jpg'):\n",
        "            label = label_dict[filename[0]]  # Mengambil huruf pertama sebagai label\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        img_array, label = load_and_label_image(image_path, label)\n",
        "        images.append(img_array)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), to_categorical(labels)\n",
        "\n",
        "# Contoh penggunaan\n",
        "image_dir = '/content/drive/MyDrive/Braille_Dataset'#my google drive data set\n",
        "X, y = generate_labels_from_filenames(image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D15JNKaPFNB6"
      },
      "outputs": [],
      "source": [
        "# split data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verifikasi pembagian\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl6qhCY-FR3L"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "model = keras.Sequential([\n",
        "    # convo, pool dan norm pertama\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', strides=(1, 1), activation='relu', input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    # convo, pool dan norm kedua\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', strides=(1,1), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.2, input_shape=(28,1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    # convo, pool dan norm ketiga\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', strides=(1,1), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.25, input_shape=(28,1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    #flatten\n",
        "    keras.layers.Flatten(),\n",
        "\n",
        "    #dense layer to connect and decress overfitting\n",
        "    keras.layers.Dense(units=512, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5, input_shape=(28,1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Dense(units=288, activation=\"relu\"),\n",
        "    keras.layers.Dense(units=27, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WNrlYR9GX1d"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO4rbiUPGe79"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=X_train,\n",
        "                    y=y_train,\n",
        "                    epochs=100,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8hp-EaGiUY"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6fZ0CA1NKN3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def sliding_window_with_classification(image, cnn_model, step_size=5, initial_box_size=20, max_box_size=100):\n",
        "    height, width = image.shape\n",
        "    detected_characters = []\n",
        "    box_size = initial_box_size\n",
        "    extracted_boxes = []\n",
        "\n",
        "    while box_size <= max_box_size:\n",
        "        has_detection = False\n",
        "        for y in range(0, height - box_size + 1, step_size):\n",
        "            for x in range(0, width - box_size + 1, step_size):\n",
        "                roi = image[y:y + box_size, x:x + box_size]\n",
        "                roi_resized = cv2.resize(roi, (28, 28))\n",
        "                roi_normalized = roi_resized / 255.0\n",
        "                roi_input = np.expand_dims(roi_normalized, axis=(0, -1))\n",
        "                prediction = cnn_model.predict(roi_input, verbose=0)\n",
        "                predicted_class = np.argmax(prediction)\n",
        "                confidence = np.max(prediction)\n",
        "\n",
        "                if predicted_class != 26 and confidence > 0.5:\n",
        "                    has_detection = True\n",
        "                    detected_characters.append((predicted_class, confidence, (x, y, x + box_size, y + box_size)))\n",
        "                    extracted_boxes.append((roi_resized, (x, y, x + box_size, y + box_size)))\n",
        "\n",
        "        if has_detection:\n",
        "            break\n",
        "        box_size += step_size\n",
        "\n",
        "    return detected_characters, extracted_boxes\n",
        "def arrange_characters_to_sentence(detected_characters):\n",
        "    detected_characters.sort(key=lambda x: (x[2][1], x[2][0]))\n",
        "    sentence = ''.join([chr(65 + char[0]) for char in detected_characters])\n",
        "    return sentence\n",
        "def process_braille_image(image_path, cnn_model_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Gambar tidak ditemukan\")\n",
        "    cnn_model = tf.keras.models.load_model(cnn_model_path)\n",
        "    detected_characters, extracted_boxes = sliding_window_with_classification(\n",
        "        image, cnn_model, step_size=10, initial_box_size=20, max_box_size=100\n",
        "    )\n",
        "    sentence = arrange_characters_to_sentence(detected_characters)\n",
        "    print(\"Kalimat yang terdeteksi:\", sentence)\n",
        "    for _, _, (x1, y1, x2, y2) in detected_characters:\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow(\"Detected Bounding Boxes\", image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3J7y2p2OepR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}